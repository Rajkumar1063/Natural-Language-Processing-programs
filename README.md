# Natural-Language-Processing-programs
EXPERIMENTS NUMBERS
1. Perform the following task using NLTK: Tokenize and tag some text, identify named
entities, display a parse tree and find the ambiguity of the sentence using parse tree.
2. Perform t-Test and Chi-Square test to check whether a given sequence of words is a
collocation or not.
3. Implement the decision rule-based Na√Øve Bayes disambiguation method to find the sense
of an ambiguous word with the given training set.
4. Implement the Hindle and Rooth algorithm for solving the attachment ambiguity problem.
5. Implement the forward and backward procedures using Hidden Markov Model to find the
probability of a word sequence.
6. Implement the Viterbi algorithm to find the probability of a word sequence, and infer the
best tag sequence using Hidden Markov Model.
7. Implement the Probabilistic Context Free Grammar (PCFG) and find the inside probability
of a word sequence using the CYK algorithm.
8. Construct the parse tree for the given sentence using Viterbi PCFG algorithm.
9. Apply the Multi-Layer Perceptron to the task of classifying surnames to their country of
origin.
SASTRA Deemed to be University
10. Design text generator using LSTMs and generate 30 words based on the input provided
by the users with available corpus.
11. Design RNN based Python machine translation system.
